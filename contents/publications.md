## On AI: 
**LLMs and their Fundamental Limitations**
- [Part 0: Series Introduction](https://hackmd.io/@LFNB9ifoT024aMHXU49sog/BJT-UHkeJl) - Overview and reading guide for the entire series
- [Part 1: Foundations and Scaling Laws](https://hackmd.io/@LFNB9ifoT024aMHXU49sog/Bkh_RwLdC) - Sentences as linearized graphs and the principles behind scaling laws
- [Part 2: Architecture and Mechanisms](https://hackmd.io/@LFNB9ifoT024aMHXU49sog/ry7hnCyb1e) - Holistic view of Transformer architecture, attention, and Feed-Forward Networks
- [Part 3: Recent Developments and Emerging Behaviors](https://hackmd.io/dhyFHBl6Q7qs0KrT7g2ghQ) - Survey of advancements and unexpected behaviors in scaled models
- [Part 4: Fundamental Limitations and Future Directions](https://hackmd.io/70THl1F8T9C4b6VEa2L3eQ) - Analysis of core LLM limitations and implications for AI development
- [Part 5: Series Conclusion](https://hackmd.io/@LFNB9ifoT024aMHXU49sog/HJnhXiJGJl) - Concluding remarks and areas of innovations needed

## Other random stuff
- [Consciousness: A Computational Perspective (hackmd)](https://hackmd.io/@LFNB9ifoT024aMHXU49sog/S1SYuF3yZe)

